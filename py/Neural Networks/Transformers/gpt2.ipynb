{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T12:37:36.216319Z",
     "start_time": "2024-06-20T12:37:36.202808Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tinycss2.tokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dataclasses import dataclass\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ac08c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "# Sample Model\n",
    "class SampleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SampleModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc = nn.Linear(32 * 8 * 8, 10)  # Assuming input is 8x8 after convs\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Extract layers\n",
    "model = SampleModel()\n",
    "layers = list(model.named_modules())[1:]  # Skip top-level model itself\n",
    "\n",
    "# Create Graph\n",
    "G = nx.DiGraph()\n",
    "positions = {}\n",
    "\n",
    "for i, (name, layer) in enumerate(layers):\n",
    "    layer_name = f\"{name}\\n({layer.__class__.__name__})\"\n",
    "    G.add_node(layer_name)\n",
    "    positions[layer_name] = (0, -i)\n",
    "\n",
    "    if i > 0:\n",
    "        prev_name = f\"{layers[i - 1][0]}\\n({layers[i - 1][1].__class__.__name__})\"\n",
    "        G.add_edge(prev_name, layer_name)\n",
    "\n",
    "# Draw\n",
    "plt.figure(figsize=(6, len(layers) * 0.6))\n",
    "nx.draw(G, positions, with_labels=True, node_size=4000, node_color=\"lightblue\", edge_color=\"black\",\n",
    "        font_size=10, font_weight=\"bold\", verticalalignment=\"center\")\n",
    "plt.title(\"Neural Network Architecture\", fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9342887e02f8e2ad",
   "metadata": {},
   "source": [
    "In GPT positional embedding were fixed to sin/cos of varying freq. but for GPT2 they are params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f0718b4dc069b11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T12:37:38.627284Z",
     "start_time": "2024-06-20T12:37:36.242900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error importing huggingface_hub.hf_api: cannot import name 'BaseFileLock' from 'filelock' (unknown location)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'BaseFileLock' from 'filelock' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline,set_seed\n\u001b[0;32m      3\u001b[0m generator \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m'\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m set_seed(\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Haroon\\miniconda3\\envs\\.conda\\Lib\\site-packages\\transformers\\__init__.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[0;32m     29\u001b[0m     _LazyModule,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m     logging,\n\u001b[0;32m     49\u001b[0m )\n\u001b[0;32m     52\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Haroon\\miniconda3\\envs\\.conda\\Lib\\site-packages\\transformers\\dependency_versions_check.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependency_versions_table\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[0;32m     25\u001b[0m pkgs_to_check_at_runtime \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtqdm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyyaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     38\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\Haroon\\miniconda3\\envs\\.conda\\Lib\\site-packages\\transformers\\utils\\__init__.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfunctools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m lru_cache\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FrozenSet\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_full_repo_name  \u001b[38;5;66;03m# for backward compatibility\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HF_HUB_DISABLE_TELEMETRY \u001b[38;5;28;01mas\u001b[39;00m DISABLE_TELEMETRY  \u001b[38;5;66;03m# for backward compatibility\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m version\n",
      "File \u001b[1;32mc:\\Users\\Haroon\\miniconda3\\envs\\.conda\\Lib\\site-packages\\huggingface_hub\\__init__.py:520\u001b[0m, in \u001b[0;36m_attach.<locals>.__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    518\u001b[0m submod_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_to_modules[name]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 520\u001b[0m     submod \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubmod_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    522\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError importing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubmod_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Haroon\\miniconda3\\envs\\.conda\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Haroon\\miniconda3\\envs\\.conda\\Lib\\site-packages\\huggingface_hub\\hf_api.py:50\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm \u001b[38;5;28;01mas\u001b[39;00m base_tqdm\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconcurrent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m thread_map\n\u001b[1;32m---> 50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_commit_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     51\u001b[0m     CommitOperation,\n\u001b[0;32m     52\u001b[0m     CommitOperationAdd,\n\u001b[0;32m     53\u001b[0m     CommitOperationCopy,\n\u001b[0;32m     54\u001b[0m     CommitOperationDelete,\n\u001b[0;32m     55\u001b[0m     _fetch_files_to_copy,\n\u001b[0;32m     56\u001b[0m     _fetch_upload_modes,\n\u001b[0;32m     57\u001b[0m     _prepare_commit_payload,\n\u001b[0;32m     58\u001b[0m     _upload_lfs_files,\n\u001b[0;32m     59\u001b[0m     _warn_on_overwriting_operations,\n\u001b[0;32m     60\u001b[0m )\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inference_endpoints\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InferenceEndpoint, InferenceEndpointType\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_multi_commits\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     63\u001b[0m     MULTI_COMMIT_PR_CLOSE_COMMENT_FAILURE_BAD_REQUEST_TEMPLATE,\n\u001b[0;32m     64\u001b[0m     MULTI_COMMIT_PR_CLOSE_COMMENT_FAILURE_NO_CHANGES_TEMPLATE,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     73\u001b[0m     plan_multi_commits,\n\u001b[0;32m     74\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Haroon\\miniconda3\\envs\\.conda\\Lib\\site-packages\\huggingface_hub\\_commit_api.py:19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconcurrent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m thread_map\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ENDPOINT, HF_HUB_ENABLE_HF_TRANSFER\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_download\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m hf_hub_url\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlfs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UploadInfo, lfs_upload, post_lfs_batch_info\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     22\u001b[0m     FORBIDDEN_FOLDERS,\n\u001b[0;32m     23\u001b[0m     EntryNotFoundError,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m     validate_hf_hub_args,\n\u001b[0;32m     31\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Haroon\\miniconda3\\envs\\.conda\\Lib\\site-packages\\huggingface_hub\\file_download.py:22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401 # for backward compatibility\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_local_folder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     get_local_download_paths,\n\u001b[0;32m     24\u001b[0m     read_download_metadata,\n\u001b[0;32m     25\u001b[0m     write_download_metadata,\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     DEFAULT_ETAG_TIMEOUT,\n\u001b[0;32m     29\u001b[0m     DEFAULT_REQUEST_TIMEOUT,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     46\u001b[0m     REPO_TYPES_URL_PREFIXES,\n\u001b[0;32m     47\u001b[0m )\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     49\u001b[0m     EntryNotFoundError,\n\u001b[0;32m     50\u001b[0m     FileMetadataError,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     78\u001b[0m     validate_hf_hub_args,\n\u001b[0;32m     79\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Haroon\\miniconda3\\envs\\.conda\\Lib\\site-packages\\huggingface_hub\\_local_folder.py:60\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m WeakFileLock\n\u001b[0;32m     63\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mLocalDownloadFilePaths\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Haroon\\miniconda3\\envs\\.conda\\Lib\\site-packages\\huggingface_hub\\utils\\__init__.py:40\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_chunk_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m chunk_iterable\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_datetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parse_datetime\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_errors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     41\u001b[0m     BadRequestError,\n\u001b[0;32m     42\u001b[0m     DisabledRepoError,\n\u001b[0;32m     43\u001b[0m     EntryNotFoundError,\n\u001b[0;32m     44\u001b[0m     FileMetadataError,\n\u001b[0;32m     45\u001b[0m     GatedRepoError,\n\u001b[0;32m     46\u001b[0m     HfHubHTTPError,\n\u001b[0;32m     47\u001b[0m     LocalEntryNotFoundError,\n\u001b[0;32m     48\u001b[0m     RepositoryNotFoundError,\n\u001b[0;32m     49\u001b[0m     RevisionNotFoundError,\n\u001b[0;32m     50\u001b[0m     hf_raise_for_status,\n\u001b[0;32m     51\u001b[0m )\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_experimental\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fixes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SoftTemporaryDirectory, WeakFileLock, yaml_dump\n",
      "File \u001b[1;32mc:\\Users\\Haroon\\miniconda3\\envs\\.conda\\Lib\\site-packages\\huggingface_hub\\utils\\_errors.py:6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrequests\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HTTPError, Response\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fixes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m JSONDecodeError\n\u001b[0;32m      9\u001b[0m REPO_API_REGEX \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     10\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m        # staging or production endpoint\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     flags\u001b[38;5;241m=\u001b[39mre\u001b[38;5;241m.\u001b[39mVERBOSE,\n\u001b[0;32m     22\u001b[0m )\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mFileMetadataError\u001b[39;00m(\u001b[38;5;167;01mOSError\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\Haroon\\miniconda3\\envs\\.conda\\Lib\\site-packages\\huggingface_hub\\utils\\_fixes.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Callable, Generator, Optional, Union\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01myaml\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfilelock\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseFileLock, FileLock, Timeout\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m constants\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m logging\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'BaseFileLock' from 'filelock' (unknown location)"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline,set_seed\n",
    "\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(42)\n",
    "generator(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd41cc223bc10f60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T12:37:39.949797Z",
     "start_time": "2024-06-20T12:37:38.627284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error importing huggingface_hub.hf_api: cannot import name 'BaseFileLock' from 'filelock' (unknown location)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'BaseFileLock' from 'filelock' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GPT2LMHeadModel\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m GPT2LMHeadModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mstate_dict()\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\Users\\Haroon\\miniconda3\\envs\\.conda\\Lib\\site-packages\\transformers\\__init__.py:26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[0;32m     29\u001b[0m     _LazyModule,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m     logging,\n\u001b[0;32m     49\u001b[0m )\n\u001b[0;32m     52\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Haroon\\miniconda3\\envs\\.conda\\Lib\\site-packages\\transformers\\dependency_versions_check.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependency_versions_table\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[0;32m     25\u001b[0m pkgs_to_check_at_runtime \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtqdm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyyaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     38\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\Haroon\\miniconda3\\envs\\.conda\\Lib\\site-packages\\transformers\\utils\\__init__.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfunctools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m lru_cache\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FrozenSet\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_full_repo_name  \u001b[38;5;66;03m# for backward compatibility\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HF_HUB_DISABLE_TELEMETRY \u001b[38;5;28;01mas\u001b[39;00m DISABLE_TELEMETRY  \u001b[38;5;66;03m# for backward compatibility\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m version\n",
      "File \u001b[1;32mc:\\Users\\Haroon\\miniconda3\\envs\\.conda\\Lib\\site-packages\\huggingface_hub\\__init__.py:520\u001b[0m, in \u001b[0;36m_attach.<locals>.__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    518\u001b[0m submod_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_to_modules[name]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 520\u001b[0m     submod \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubmod_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    522\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError importing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubmod_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Haroon\\miniconda3\\envs\\.conda\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Haroon\\miniconda3\\envs\\.conda\\Lib\\site-packages\\huggingface_hub\\hf_api.py:50\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm \u001b[38;5;28;01mas\u001b[39;00m base_tqdm\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconcurrent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m thread_map\n\u001b[1;32m---> 50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_commit_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     51\u001b[0m     CommitOperation,\n\u001b[0;32m     52\u001b[0m     CommitOperationAdd,\n\u001b[0;32m     53\u001b[0m     CommitOperationCopy,\n\u001b[0;32m     54\u001b[0m     CommitOperationDelete,\n\u001b[0;32m     55\u001b[0m     _fetch_files_to_copy,\n\u001b[0;32m     56\u001b[0m     _fetch_upload_modes,\n\u001b[0;32m     57\u001b[0m     _prepare_commit_payload,\n\u001b[0;32m     58\u001b[0m     _upload_lfs_files,\n\u001b[0;32m     59\u001b[0m     _warn_on_overwriting_operations,\n\u001b[0;32m     60\u001b[0m )\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inference_endpoints\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InferenceEndpoint, InferenceEndpointType\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_multi_commits\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     63\u001b[0m     MULTI_COMMIT_PR_CLOSE_COMMENT_FAILURE_BAD_REQUEST_TEMPLATE,\n\u001b[0;32m     64\u001b[0m     MULTI_COMMIT_PR_CLOSE_COMMENT_FAILURE_NO_CHANGES_TEMPLATE,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     73\u001b[0m     plan_multi_commits,\n\u001b[0;32m     74\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Haroon\\miniconda3\\envs\\.conda\\Lib\\site-packages\\huggingface_hub\\_commit_api.py:19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconcurrent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m thread_map\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ENDPOINT, HF_HUB_ENABLE_HF_TRANSFER\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_download\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m hf_hub_url\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlfs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m UploadInfo, lfs_upload, post_lfs_batch_info\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     22\u001b[0m     FORBIDDEN_FOLDERS,\n\u001b[0;32m     23\u001b[0m     EntryNotFoundError,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m     validate_hf_hub_args,\n\u001b[0;32m     31\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Haroon\\miniconda3\\envs\\.conda\\Lib\\site-packages\\huggingface_hub\\file_download.py:22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__  \u001b[38;5;66;03m# noqa: F401 # for backward compatibility\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_local_folder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     get_local_download_paths,\n\u001b[0;32m     24\u001b[0m     read_download_metadata,\n\u001b[0;32m     25\u001b[0m     write_download_metadata,\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     DEFAULT_ETAG_TIMEOUT,\n\u001b[0;32m     29\u001b[0m     DEFAULT_REQUEST_TIMEOUT,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     46\u001b[0m     REPO_TYPES_URL_PREFIXES,\n\u001b[0;32m     47\u001b[0m )\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     49\u001b[0m     EntryNotFoundError,\n\u001b[0;32m     50\u001b[0m     FileMetadataError,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     78\u001b[0m     validate_hf_hub_args,\n\u001b[0;32m     79\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Haroon\\miniconda3\\envs\\.conda\\Lib\\site-packages\\huggingface_hub\\_local_folder.py:60\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m WeakFileLock\n\u001b[0;32m     63\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mLocalDownloadFilePaths\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Haroon\\miniconda3\\envs\\.conda\\Lib\\site-packages\\huggingface_hub\\utils\\__init__.py:40\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_chunk_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m chunk_iterable\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_datetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parse_datetime\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_errors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     41\u001b[0m     BadRequestError,\n\u001b[0;32m     42\u001b[0m     DisabledRepoError,\n\u001b[0;32m     43\u001b[0m     EntryNotFoundError,\n\u001b[0;32m     44\u001b[0m     FileMetadataError,\n\u001b[0;32m     45\u001b[0m     GatedRepoError,\n\u001b[0;32m     46\u001b[0m     HfHubHTTPError,\n\u001b[0;32m     47\u001b[0m     LocalEntryNotFoundError,\n\u001b[0;32m     48\u001b[0m     RepositoryNotFoundError,\n\u001b[0;32m     49\u001b[0m     RevisionNotFoundError,\n\u001b[0;32m     50\u001b[0m     hf_raise_for_status,\n\u001b[0;32m     51\u001b[0m )\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_experimental\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fixes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SoftTemporaryDirectory, WeakFileLock, yaml_dump\n",
      "File \u001b[1;32mc:\\Users\\Haroon\\miniconda3\\envs\\.conda\\Lib\\site-packages\\huggingface_hub\\utils\\_errors.py:6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrequests\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HTTPError, Response\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fixes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m JSONDecodeError\n\u001b[0;32m      9\u001b[0m REPO_API_REGEX \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     10\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m        # staging or production endpoint\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     flags\u001b[38;5;241m=\u001b[39mre\u001b[38;5;241m.\u001b[39mVERBOSE,\n\u001b[0;32m     22\u001b[0m )\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mFileMetadataError\u001b[39;00m(\u001b[38;5;167;01mOSError\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\Haroon\\miniconda3\\envs\\.conda\\Lib\\site-packages\\huggingface_hub\\utils\\_fixes.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Callable, Generator, Optional, Union\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01myaml\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfilelock\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseFileLock, FileLock, Timeout\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m constants\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m logging\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'BaseFileLock' from 'filelock' (unknown location)"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "for k,v in model.state_dict().items():\n",
    "  print(k,v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bb54da450e1b94",
   "metadata": {},
   "source": [
    "From scratch\n",
    "\n",
    "<img src=\"model.png\" alt=model>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "966edae7581db048",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T13:05:03.065133Z",
     "start_time": "2024-06-20T13:05:03.038136Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "  def __init__(self, config):\n",
    "    super().__init__()\n",
    "    self.c_fc = nn.Linear(config.n_embd, 4*config.n_embd)\n",
    "    self.gelu = nn.GELU()\n",
    "      #GELU(approximate='tanh')  # gaussian Rectifier approx by tanh (original was slow in tf)\n",
    "    self.c_proj = nn.Linear(4*config.n_embd, config.n_embd)\n",
    "      \n",
    "  def forward(self, x):\n",
    "    x = self.c_fc(x)\n",
    "    x = self.gelu(x)\n",
    "    x = self.c_proj(x)\n",
    "    return x\n",
    "  \n",
    "class CausalSelfAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        # key, query, value projections for all heads, but in a batch\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n",
    "        # output projection\n",
    "        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n",
    "        # regularization\n",
    "        self.attn_dropout = nn.Dropout(config.dropout)\n",
    "        self.resid_dropout = nn.Dropout(config.dropout)\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "        self.dropout = config.dropout\n",
    "        # flash attention make GPU go brrrrr but support is only in PyTorch >= 2.0\n",
    "        self.flash = hasattr(torch.nn.functional, 'scaled_dot_product_attention')\n",
    "        if not self.flash:\n",
    "            print(\"WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\")\n",
    "            # causal mask to ensure that attention is only applied to the left in the input sequence\n",
    "            self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size).view(1, 1, config.block_size, config.block_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
    "\n",
    "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
    "        q, k, v  = self.c_attn(x).split(self.n_embd, dim=2)\n",
    "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
    "\n",
    "        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n",
    "        if self.flash:\n",
    "            # efficient attention using Flash Attention CUDA kernels\n",
    "            y = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.dropout if self.training else 0, is_causal=True)\n",
    "        else:\n",
    "            # manual implementation of attention\n",
    "            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
    "            att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
    "            att = F.softmax(att, dim=-1)\n",
    "            att = self.attn_dropout(att)\n",
    "            y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
    "\n",
    "        # output projection\n",
    "        y = self.resid_dropout(self.c_proj(y))\n",
    "        return y\n",
    "\n",
    "class Block(nn.Module): # transformer block\n",
    "  def __init__(self, config):\n",
    "    super().__init__()\n",
    "    self.ln_1 = nn.LayerNorm(config.n_embd)  \n",
    "    self.attn = CausalSelfAttention(config)\n",
    "    self.ln_2 = nn.LayerNorm(config.n_embd)  \n",
    "    self.mlp = MLP(config)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = x + self.attn(self.ln_1(x))  # residual connections according to diagram plus ln after attn i.e. ln in residuals\n",
    "    x = x + self.mlp(self.ln_2(x))\n",
    "    return x\n",
    "      \n",
    "@dataclass\n",
    "class GPTConfig:   # gpt 124M\n",
    "  block_size = 1024   # max sequence length\n",
    "  vocab_size = 50257  # 50k BPE + 256 utf-8 + 1 <|endoftext|>\n",
    "  n_layer = 12        \n",
    "  n_head = 12\n",
    "  n_embd = 768\n",
    "  dropout = 0.2\n",
    "  bias = True\n",
    "\n",
    "class GPT(nn.Module):\n",
    "  def __init__(self, config):\n",
    "    super().__init__()\n",
    "    self.config = config\n",
    "    \n",
    "    self.transformer = nn.ModuleDict(     # submodule indexing\n",
    "      dict(\n",
    "        wte = nn.Embedding(config.vocab_size, config.n_embd),               # weight token embd                  nn.Embedding -> wrapper for array of nums\n",
    "        wpe = nn.Embedding(config.block_size, config.n_embd),               # weight pos embd\n",
    "        h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),  # hidden         # index using numeric as per statedict\n",
    "        ln_f = nn.LayerNorm(config.n_embd),                                 # additional layernorm\n",
    "      ))\n",
    "    self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)  # classifier/head   n_embd -> vocab size\n",
    "  \n",
    "  def forward(self, idx, targets =None):\n",
    "    B,T = idx.size()\n",
    "    assert T <= self.config.block_size, f\"Block size {self.config.block_size} exceeds block size {self.config.block_size}\"\n",
    "    pos = torch.arange(0,T,dtype=torch.long,device=idx.device) #shape T\n",
    "    pos_emb = self.transformer.wpe(pos)                        # shape T,n_embd\n",
    "    tok_emb = self.transformer.wte(idx)                        # shape B,T,n_embd\n",
    "    x = tok_emb + pos_emb  # broadcast\n",
    "    \n",
    "    for block in self.transformer.h:\n",
    "      x = block(x)\n",
    "    x = self.transformer.ln_f(x)  # forward final layernorm\n",
    "    logits = self.lm_head(x)                                  # B,T,vocab_size\n",
    "    loss = None\n",
    "    if targets is not None:\n",
    "      loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))     # cross entropy doesnt prefer multidimensional inputs   logits = B*T,vocab\n",
    "    return logits,loss\n",
    "  \n",
    "  @classmethod\n",
    "  def from_pretrained(cls, model_type, override_args=None):  # load pretrained\n",
    "        assert model_type in {'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'}\n",
    "        override_args = override_args or {} # default to empty dict\n",
    "        # only dropout can be overridden see more notes below\n",
    "        from transformers import GPT2LMHeadModel\n",
    "        print(\"loading weights from pretrained gpt: %s\" % model_type)\n",
    "\n",
    "        # n_layer, n_head and n_embd are determined from model_type\n",
    "        config_args = {\n",
    "            'gpt2':         dict(n_layer=12, n_head=12, n_embd=768),  # 124M params\n",
    "            'gpt2-medium':  dict(n_layer=24, n_head=16, n_embd=1024), # 350M params\n",
    "            'gpt2-large':   dict(n_layer=36, n_head=20, n_embd=1280), # 774M params\n",
    "            'gpt2-xl':      dict(n_layer=48, n_head=25, n_embd=1600), # 1558M params\n",
    "        }[model_type]\n",
    "        print(\"forcing vocab_size=50257, block_size=1024, bias=True\")\n",
    "        config_args['vocab_size'] = 50257 # always 50257 for GPT model checkpoints\n",
    "        config_args['block_size'] = 1024 # always 1024 for GPT model checkpoints\n",
    "        # create a from-scratch initialized minGPT model\n",
    "        config = GPTConfig()\n",
    "        model = GPT(config)\n",
    "        sd = model.state_dict()\n",
    "        sd_keys = sd.keys()\n",
    "        sd_keys = [k for k in sd_keys if not k.endswith('.attn.bias')] # discard this mask / buffer, not a param\n",
    "\n",
    "        # init a huggingface/transformers model\n",
    "        model_hf = GPT2LMHeadModel.from_pretrained(model_type)\n",
    "        sd_hf = model_hf.state_dict()\n",
    "\n",
    "        # copy while ensuring all the parameters are aligned and match in names and shapes\n",
    "        sd_keys_hf = sd_hf.keys()\n",
    "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.masked_bias')] # ignore these, just a buffer\n",
    "        sd_keys_hf = [k for k in sd_keys_hf if not k.endswith('.attn.bias')] # same, just the mask (buffer)\n",
    "        transposed = ['attn.c_attn.weight', 'attn.c_proj.weight', 'mlp.c_fc.weight', 'mlp.c_proj.weight']\n",
    "        # basically the openai checkpoints use a \"Conv1D\" module, but we only want to use a vanilla Linear\n",
    "        # this means that we have to transpose these weights when we import them\n",
    "        assert len(sd_keys_hf) == len(sd_keys), f\"mismatched keys: {len(sd_keys_hf)} != {len(sd_keys)}\"\n",
    "        for k in sd_keys_hf:\n",
    "            if any(k.endswith(w) for w in transposed):\n",
    "                # special treatment for the Conv1D weights we need to transpose\n",
    "                assert sd_hf[k].shape[::-1] == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sd_hf[k].t())\n",
    "            else:\n",
    "                # vanilla copy over the other parameters\n",
    "                assert sd_hf[k].shape == sd[k].shape\n",
    "                with torch.no_grad():\n",
    "                    sd[k].copy_(sd_hf[k])\n",
    "\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e7d28adfde0f4f",
   "metadata": {},
   "source": [
    "Starting with Pretrained version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ace10f53ddd5fd55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T12:37:42.268481Z",
     "start_time": "2024-06-20T12:37:40.110719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights from pretrained gpt: gpt2\n",
      "forcing vocab_size=50257, block_size=1024, bias=True\n",
      "GPT(\n",
      "  (transformer): ModuleDict(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): CausalSelfAttention(\n",
      "          (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (attn_dropout): Dropout(p=0.2, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): MLP(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = GPT.from_pretrained('gpt2')\n",
    "print(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4394bea3c03db8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T12:37:42.458698Z",
     "start_time": "2024-06-20T12:37:42.269565Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.2, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_return_sequences = 5\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "max_length = 30\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "907c3b17a28aa754",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T12:37:42.730299Z",
     "start_time": "2024-06-20T12:37:42.458698Z"
    }
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.get_encoding('gpt2')\n",
    "tokens = enc.encode(\"Hello World\")\n",
    "tokens =torch.tensor(tokens,dtype=torch.long,device=device)\n",
    "tokens = tokens.unsqueeze(0).repeat(num_return_sequences,1) #idx\n",
    "x = tokens.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3196e01a86f5cdf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T12:37:43.226179Z",
     "start_time": "2024-06-20T12:37:42.730299Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Haroon\\AppData\\Local\\Temp\\ipykernel_13704\\218594534.py:50: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  y = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.dropout if self.training else 0, is_causal=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World, the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Hello World, the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Hello World, the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Hello World, the the the the the the the the the the the the the the the the the the the the the the the the the the the\n",
      "Hello World, the the the the the the the the the the the the the the the the the the the the the the the the the the the\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "while x.size(1) < max_length:\n",
    "  with torch.no_grad():\n",
    "    logits = model(x)\n",
    "    logits = logits[:, -1, :] # take logits at end\n",
    "    probs = F.softmax(logits, dim=-1) \n",
    "    topx_probs, topx_tokens = torch.topk(probs, 50,dim=-1)  #huggingface default /keep top 50\n",
    "    ix = torch.multinomial(topx_probs,1)  # select from top\n",
    "    xcol = torch.gather(topx_tokens, -1, ix)  #gather corresponding index\n",
    "    x = torch.cat((x,xcol),dim=1) # append\n",
    "\n",
    "\n",
    "for i in range(num_return_sequences):\n",
    "  tokens = x[i,:max_length].tolist() #rows\n",
    "  decoded = enc.decode(tokens)\n",
    "  print(decoded)  # weird?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e2b2beb6532b8d",
   "metadata": {},
   "source": [
    "Now train from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9797188285d14bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T13:05:18.067989Z",
     "start_time": "2024-06-20T13:05:18.057944Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "B,T = 4,32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27ed6674d46ffc08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T13:05:18.695008Z",
     "start_time": "2024-06-20T13:05:18.612003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2514, 9074, 13, 8858, 8270, 11, 4492, 13, 220, 198, 1273, 13]\n",
      "To Mrs. Savi\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "enc = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "data = open('input.txt','r',encoding='utf-8').read()[:1000]   # start with only 1000 chars\n",
    "tokens = enc.encode(data)\n",
    "print(tokens[:12]); print(data[:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "797fd2c3e0790c29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T13:05:19.126463Z",
     "start_time": "2024-06-20T13:05:19.107733Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2514,  9074,    13,  8858,  8270,    11,  4492,    13,   220,   198,\n",
      "          1273,    13, 15722,  9228,    11,  4280,    13,  1367,   400,    11,\n",
      "          1596,    13,   198,  1639,   481, 46201,   284,  3285,   326,   645,\n",
      "          9336,   468],\n",
      "        [11791,   262,   198,  9503,   594,   434,   286,   281, 13953,   543,\n",
      "           345,   423, 11987,   351,   884,  6181,   198,   754,    65,   375,\n",
      "           654,    13,   314,  5284,   994,  7415,    11,   290,   616,   717,\n",
      "          4876,   318],\n",
      "        [  284, 19832,   198,  1820, 13674,  6621,   286,   616,  9490,   290,\n",
      "          3649,  6628,   287,   262,  1943,   198,  1659,   616, 25971,    13,\n",
      "           198,    40,   716,  1541,  1290,  5093,   286,  3576,    11,   290,\n",
      "           355,   314],\n",
      "        [ 2513,   287,   262,  6483,   286,   198,    47,  7307,  9228,    11,\n",
      "           314,  1254,   257,  4692,  7840, 28633,   711,  2402,   616, 25839,\n",
      "            11,   543,   198,  1671,  2114,   616, 25377,   290, 23816,   502,\n",
      "           351, 10974]], device='cuda:0')\n",
      "tensor([[ 9074,    13,  8858,  8270,    11,  4492,    13,   220,   198,  1273,\n",
      "            13, 15722,  9228,    11,  4280,    13,  1367,   400,    11,  1596,\n",
      "            13,   198,  1639,   481, 46201,   284,  3285,   326,   645,  9336,\n",
      "           468, 11791],\n",
      "        [  262,   198,  9503,   594,   434,   286,   281, 13953,   543,   345,\n",
      "           423, 11987,   351,   884,  6181,   198,   754,    65,   375,   654,\n",
      "            13,   314,  5284,   994,  7415,    11,   290,   616,   717,  4876,\n",
      "           318,   284],\n",
      "        [19832,   198,  1820, 13674,  6621,   286,   616,  9490,   290,  3649,\n",
      "          6628,   287,   262,  1943,   198,  1659,   616, 25971,    13,   198,\n",
      "            40,   716,  1541,  1290,  5093,   286,  3576,    11,   290,   355,\n",
      "           314,  2513],\n",
      "        [  287,   262,  6483,   286,   198,    47,  7307,  9228,    11,   314,\n",
      "          1254,   257,  4692,  7840, 28633,   711,  2402,   616, 25839,    11,\n",
      "           543,   198,  1671,  2114,   616, 25377,   290, 23816,   502,   351,\n",
      "         10974,    13]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# convert to shape B,T instead of single row\n",
    "import torch\n",
    "\n",
    "buf =  torch.tensor(tokens[:B*T + 1])  # take one extra for next token in y\n",
    "x = buf[:-1].view(B,T).to(device)   # exclude last\n",
    "y = buf[1:].view(B,T).to(device)     # start from second\n",
    "print(x); print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "153a1f1fa98de60c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T13:05:20.693005Z",
     "start_time": "2024-06-20T13:05:19.777990Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (attn_dropout): Dropout(p=0.2, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPT(GPTConfig())\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b864978df1bfc626",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-20T13:06:14.836316Z",
     "start_time": "2024-06-20T13:06:14.595097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.1579, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "logits, loss = model(x,y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c52dfa7701c1a54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
