{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T04:09:19.381760Z",
     "start_time": "2024-06-15T04:09:17.803470Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " in practice, charector level token are rarely used. instead \"chunks\"/ bytepair etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T04:09:19.491044Z",
     "start_time": "2024-06-15T04:09:19.383808Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33396219"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = open('input.txt', 'r', encoding='utf-8').read()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T04:09:19.897291Z",
     "start_time": "2024-06-15T04:09:19.492043Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33427740, 155)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = data.encode('utf-8')\n",
    "len(tokens),len(set(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T04:09:22.250715Z",
     "start_time": "2024-06-15T04:09:19.898292Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33396219"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = open('input.txt','r',encoding='utf-8').read()\n",
    "tokens = [ord(char) for char in text]\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T04:09:22.393395Z",
     "start_time": "2024-06-15T04:09:22.252716Z"
    }
   },
   "outputs": [],
   "source": [
    "def counts(id:list):\n",
    "  count = {}\n",
    "  for p in zip(id,id[1:]):\n",
    "    count[p]  = count.get(p,0) + 1\n",
    "  return count\n",
    "  \n",
    "def merge(id,top,tok):\n",
    "  nid = []\n",
    "  i = 0\n",
    "  while i < len(id):\n",
    "    if i < len(id) - 1 and id[i] == top[0] and id[i+1] == top[1]:\n",
    "      nid.append(tok)\n",
    "      i+=2\n",
    "    else:\n",
    "      nid.append(id[i])\n",
    "      i+=1\n",
    "  return nid\n",
    "# count = counts(text)\n",
    "# top = max(count,key=count.get)\n",
    "# toke = merge(text,top,256)\n",
    "# len(toke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T04:14:18.735105Z",
     "start_time": "2024-06-15T04:09:22.394395Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m merges \u001b[38;5;241m=\u001b[39m {}    \u001b[38;5;66;03m# t1,t2 -> t3\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_merge):\n\u001b[0;32m----> 8\u001b[0m   stats \u001b[38;5;241m=\u001b[39m \u001b[43mcounts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m   pair \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(stats,key\u001b[38;5;241m=\u001b[39mstats\u001b[38;5;241m.\u001b[39mget)\n\u001b[1;32m     10\u001b[0m   idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m \u001b[38;5;241m+\u001b[39m i\n",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m, in \u001b[0;36mcounts\u001b[0;34m(id)\u001b[0m\n\u001b[1;32m      2\u001b[0m count \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mid\u001b[39m,\u001b[38;5;28mid\u001b[39m[\u001b[38;5;241m1\u001b[39m:]):\n\u001b[0;32m----> 4\u001b[0m   count[p]  \u001b[38;5;241m=\u001b[39m \u001b[43mcount\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m count\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# it is tunable how many times to encode with bpe. but there are diminishing returns as vocab size will increase    this takes around 5 min for 20 merges on 3mil\n",
    "vocab_size = 276  # 20 merges\n",
    "num_merge = vocab_size - 256\n",
    "ids = list(tokens) # copy\n",
    "\n",
    "merges = {}    # t1,t2 -> t3\n",
    "for i in range(num_merge):\n",
    "  stats = counts(ids)\n",
    "  pair = max(stats,key=stats.get)\n",
    "  idx = 256 + i\n",
    "  ids = merge(ids,pair,idx)\n",
    "  merges[pair] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T04:14:21.179510Z",
     "start_time": "2024-06-15T04:14:18.737112Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(tokens)/len(ids)) , print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(101, 32): 256, (44, 32): 257, (46, 32): 258, (105, 110): 259, (116, 104): 260, (101, 114): 261, (32, 97): 262, (46, 10): 263, (111, 114): 264, (115, 32): 265, (111, 110): 266, (100, 32): 267, (97, 110): 268, (116, 32): 269, (101, 110): 270, (111, 32): 271, (32, 32): 272, (111, 102): 273, (263, 10): 274, (260, 256): 275}\n"
     ]
    }
   ],
   "source": [
    "print(merges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {idx: bytes([idx]) for idx in range(256)}\n",
    "for (p0,p1),idx in merges.items():    # needs and guaranteed after python 3.7 to be in order of insertion\n",
    "  vocab[idx] = vocab[0] + vocab[1] # concat\n",
    "def decode(ids):\n",
    "  tokens = b\"\".join(vocab[idx] for idx in ids)\n",
    "  text = tokens.decode(\"utf-8\",errors='replace')  # for char like 128 replace with ?(unknown)\n",
    "  return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text):\n",
    "  tokens = list(text.encode('utf-8'))\n",
    "  while len(tokens)>=2:\n",
    "    stats = counts(tokens)\n",
    "    pair = min(stats,key=lambda p: merges.get(p,float('inf')))\n",
    "    if pair not in merges:\n",
    "      break\n",
    "    idx = merges[pair]\n",
    "    tokens = merge(tokens,pair,idx)\n",
    "  return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab = {idx: bytes([idx]) f\u0000\u0001 idx \u0000\u0001 r\u0000\u0001ge(256)}f\u0000\u0001 (p0,p1),idx \u0000\u0001 m\u0000\u0001ges.items():\u0000\u0001\u0000\u0001# needs\u0000\u0001n\u0000\u0001guar\u0000\u0001teed\u0000\u0001ft\u0000\u0001 py\u0000\u0001\u0000\u0001 3.7 t\u0000\u0001b\u0000\u0001\u0000\u0001 \u0000\u0001d\u0000\u0001 \u0000\u0001 \u0000\u0001s\u0000\u0001ti\u0000\u0001vocab[idx] = vocab[0] + vocab[1] # c\u0000\u0001catdef decode(ids):tok\u0000\u0001\u0000\u0001= b.jo\u0000\u0001(vocab[idx] f\u0000\u0001 idx \u0000\u0001 ids)tex\u0000\u0001= tok\u0000\u0001'# f\u0000\u0001 char lik\u0000\u0001128 replac\u0000\u0001wi\u0000\u0001 ?(unknown)return text\n"
     ]
    }
   ],
   "source": [
    "print(decode(encode(\"vocab = {idx: bytes([idx]) for idx in range(256)}for (p0,p1),idx in merges.items():    # needs and guaranteed after python 3.7 to be in order of insertionvocab[idx] = vocab[0] + vocab[1] # concatdef decode(ids):tokens = b\"\".join(vocab[idx] for idx in ids)text = token'# for char like 128 replace with ?(unknown)return text\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesnt take into account abc followed by exclamations mean different i.e. abc. and abc! shouldnt be merged to x.,x!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', ' will', \"'ve\", ' split', ' this', ' in', ' words', '123']\n"
     ]
    }
   ],
   "source": [
    "import regex as re\n",
    "\n",
    "pattern = re.compile(r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\")\n",
    "print(re.findall(pattern,\"this will've split this in words123\"))       # in and ' words' will always be seperate instead of maybe 'n '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T04:20:17.767780Z",
     "start_time": "2024-06-15T04:20:17.752154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print(re.findall(pattern,\"this will've split this in words123\"))       # in and ' words' will always be seperate instead of maybe 'n '\n"
     ]
    }
   ],
   "source": [
    "# special tokens\n",
    "# 256 unicode, 50k merges, '<|endoftext|>'\n",
    "import tiktoken\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")  # gpt4\n",
    "\n",
    "print(enc.decode(enc.encode(\"\"\"print(re.findall(pattern,\"this will've split this in words123\"))       # in and ' words' will always be seperate instead of maybe 'n '\"\"\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T04:37:38.666845Z",
     "start_time": "2024-06-15T04:37:38.651220Z"
    }
   },
   "outputs": [],
   "source": [
    "# import sentencepiece as spm      # train and inference of vocabs\n",
    "# import os\n",
    "# options = dict(\n",
    "#   model_prefix=\"spm_model\",\n",
    "#   vocab_size=vocab_size,\n",
    "# #...\n",
    "# )\n",
    "# spm.SentencePieceTrainer.Train(**options)\n",
    "# sp = spm.SentencePieceProcessor()\n",
    "# sp.load('spm.model')\n",
    "# print(sp.EncodeAsPieces(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
