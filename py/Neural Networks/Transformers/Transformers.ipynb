{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T10:37:46.395952Z",
     "start_time": "2024-06-14T10:37:43.523606Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T11:41:07.415740Z",
     "start_time": "2024-06-14T11:41:07.290323Z"
    }
   },
   "source": [
    "data  = open(\"input.txt\",'r',encoding='utf-8').read()\n",
    "print(len(data))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36070473\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T11:41:08.603856Z",
     "start_time": "2024-06-14T11:41:07.965115Z"
    }
   },
   "source": [
    "chars = sorted(list(set(data)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\n",
      " !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~¡£§­°·º¼½¾¿ÆÇÉ×ÜÞàáâãäåæçèéêëìíîïðñòóôö÷ùúûüýþœЎабйнтщ،؟آابتثخدرزشعفلمنهوچکی‌—‘’“”…™\n",
      "181\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T11:41:09.170070Z",
     "start_time": "2024-06-14T11:41:09.154438Z"
    }
   },
   "source": [
    "# mappping of characters to integers\n",
    "s_i = {c:i for i,c in enumerate(chars)}\n",
    "i_s = {i:c for i,c in enumerate(chars)}\n",
    "\n",
    "def encode(x): return [s_i[c] for c in x]  # encode input string to integers\n",
    "def decode(x): return ''.join([i_s[i] for i in x])# decode integers to input string\n",
    "\n",
    "print(encode('hello'))\n",
    "print(decode([62, 29, 36, 36, 39]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[74, 71, 78, 78, 81]\n",
      "\\;BBE\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T11:41:23.843306Z",
     "start_time": "2024-06-14T11:41:19.203854Z"
    }
   },
   "source": [
    "# convert input data to tensor\n",
    "data = torch.tensor(encode(data), dtype=torch.long).to('cuda')\n",
    "print(data.shape, data.dtype)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([36070473]) torch.int64\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T11:41:25.759500Z",
     "start_time": "2024-06-14T11:41:25.743874Z"
    }
   },
   "source": [
    "# train-val split\n",
    "n = int(len(data)*0.9)\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T11:41:57.665876Z",
     "start_time": "2024-06-14T11:41:57.650246Z"
    }
   },
   "source": [
    "torch.manual_seed(42)\n",
    "block_size = 8 # time dimension of the sequence\n",
    "batch_size = 4  # number of sequences in parallel\n",
    "def create_batch(slpit):\n",
    "    data = train_data if slpit=='train' else val_data\n",
    "    ix = torch.randint(len(data)-block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x.to('cuda'),y.to('cuda')"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T11:42:44.965628Z",
     "start_time": "2024-06-14T11:42:44.841360Z"
    }
   },
   "source": [
    "torch.manual_seed(42)\n",
    "xb,yb = create_batch('train')\n",
    "class BigramModel(nn.Module):\n",
    "    def __init__(self,vocab_size ):\n",
    "        super().__init__()\n",
    "        self.token_emb_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx,targets=None):\n",
    "        logits = self.token_emb_table(idx)          # (batch, time ,channel)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B,T,C = logits.shape\n",
    "            logits = logits.view(B*T,C)             # cross entropy expects batch x channel x time\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        return logits,loss\n",
    "\n",
    "    def generate(self,idx,max_new):                 # idx -> (B,T) for current sequence\n",
    "        for _ in range(max_new):\n",
    "            logits,loss =self(idx)\n",
    "            logits = logits[:,-1,:]                 # (B,C)\n",
    "            probs = F.softmax(logits,dim=-1)\n",
    "            idx_next = torch.multinomial(probs,1)   # (B,1)\n",
    "            idx = torch.cat((idx,idx_next),dim=1)   # (B,T+1)\n",
    "        return idx\n",
    "\n",
    "m = BigramModel(vocab_size).to('cuda')\n",
    "logits,loss = m(xb,yb)\n",
    "print(logits.shape,loss)                            #(B, T, C)\n",
    "idx = torch.zeros((1,1),dtype=torch.long).to('cuda')\n",
    "print(decode(m.generate(idx, max_new=100)[0].tolist()))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 181]) tensor(5.6543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "\tک‘ëMîث-w<ÞpdÆع:#ثyDi`а½یYCخآHй§<،)د‌…‘w×BzزzچýÉDq_gê~ìaQB§}%¡+=F¿5ث<T`[-P}úG§çщzN(Çй’Kآ:Tx¡+°CÆYнä13\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T11:42:48.665373Z",
     "start_time": "2024-06-14T11:42:48.649372Z"
    }
   },
   "source": "optimizer = torch.optim.AdamW(m.parameters(),lr =1e-3)  # for smaller networks high lr(1e-3) can work ",
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T11:44:28.570180Z",
     "start_time": "2024-06-14T11:44:26.685832Z"
    }
   },
   "source": [
    "batch_size =32\n",
    "\n",
    "for i in range(1000):\n",
    "    x, y =create_batch('train')\n",
    "    logits, loss = m(x,y)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.853066921234131\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T11:44:30.866226Z",
     "start_time": "2024-06-14T11:44:30.594524Z"
    }
   },
   "source": [
    "print(decode(m.generate(idx, max_new=500)[0].tolist()))   # from the simplest model"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tjo antofn [issele, irty --\n",
      "\"bode se t y\n",
      "Gons; crs; bl owofn she. by pimus F. b)\n",
      "AThe toor - s, tmed cy s. pellwoten asemowof; astiofn, ty f orelalle pe\"BRGuricicalochof Sted tha*t Matofame jöl.] hin;\n",
      "\n",
      "Gar cinon\"The ielotionectis.] ponthin, men. pldlen.]\n",
      "z\"thon; iverola.\n",
      "1.\n",
      "dorsethea*ty.\n",
      "Acurome t. bouina o\n",
      "\n",
      "\n",
      " ve of*t hertrkesiete mo wamanor. aristin. ioroonsultirthivin'dac\"F.\n",
      "Onecus e ELansed\"OFrhefangunth! kice sholoncas. chn. ticrar; mis ocqu a EL. tmuba oue-\n",
      "Ratish, tothe a St?! locing.), min\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplest way for tokens to communicate with previous (self attention)\n",
    "# communicate with only previous \n",
    "* average of all vectors before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "\n",
      "tensor([[3., 2.],\n",
      "        [5., 2.],\n",
      "        [3., 4.]])\n",
      "\n",
      "tensor([[3.0000, 2.0000],\n",
      "        [4.0000, 2.0000],\n",
      "        [3.6667, 2.6667]])\n"
     ]
    }
   ],
   "source": [
    "# trick to create a lower triangular matrix for attention\n",
    "a = torch.tril(torch.ones(3,3))      # lower triangular matrix\n",
    "a = a/ torch.sum(a,dim=1,keepdim=True)  # normalize\n",
    "b= torch.randint(0,10,(3,2)).float()\n",
    "c = a@b  #  each element of c is mean of previous elements of b\n",
    "print(f'{a}\\n')\n",
    "print(f'{b}\\n')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # can also be done as\n",
    "# a = torch.tril(torch.ones(3,3)).float()      # lower triangular matrix\n",
    "# w =torch.zeros(3,3).float()\n",
    "# w =w.masked_fill(a==0, float('-inf')) # replace 0 with -inf\n",
    "# w = torch.softmax(b,dim=-1)  # softmax on negative values\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T11:03:50.423612Z",
     "start_time": "2024-06-14T11:03:50.376735Z"
    }
   },
   "source": [
    "# self attention\n",
    "torch.manual_seed(42)\n",
    "B,T,C = 4,8,32\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "head_size = 16\n",
    "key = nn.Linear(C,head_size,bias=False)  # what to look for\n",
    "query = nn.Linear(C,head_size,bias=False) # what to look at\n",
    "value = nn.Linear(C,head_size,bias=False) # what to output\n",
    "k = key(x)\n",
    "q = query(x)\n",
    "v = value(x)\n",
    "wei = q @ k.transpose(-1,-2)  # (B, T, 16) -> (B, 16, T)  # affinites of each element with each other\n",
    "wei = wei / (head_size**0.5)  # scale to make variance 1 \n",
    "# as softmax with encode the large values as small values will be 0\n",
    "\n",
    "\n",
    "trill = torch.tril(torch.ones(T,T)).float()\n",
    "# wei = torch.zeros(T,T).float()\n",
    "wei = wei.masked_fill(trill==0, float('-inf'))  # make next elements not visible\n",
    "wei = torch.softmax(wei,dim=-1)\n",
    "out =wei@v\n",
    "out.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# residual connection\n",
    " * for larger networks \n",
    " * alow to optimise better by adding a computational path in between\n",
    " * this connection starts by negligible contribution at start then gradually increases\n",
    "\n",
    " `` 2..03 at this stage``"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T11:03:54.251204Z",
     "start_time": "2024-06-14T11:03:54.219563Z"
    }
   },
   "source": [
    "class layerNorm1d:\n",
    "    \"\"\"similar to batch norm but along rows and no buffers\"\"\"\n",
    "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "        self.eps = eps\n",
    "        # parameters (trained with backprop)\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # calculate the forward pass\n",
    "\n",
    "        xmean = x.mean(1, keepdim=True) # normalize the rows instead of columns # layer norm\n",
    "        xvar = x.var(1, keepdim=True)\n",
    "        xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "        return self.out\n",
    "\n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]\n"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this plus increasing context size and network size\n",
    "# also add dropout layer\n",
    "\n",
    "`now 1.615`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
