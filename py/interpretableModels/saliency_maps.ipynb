{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Qwf54ZqY-SX"
   },
   "source": [
    "# XAI CODE DEMO\n",
    "\n",
    "## Explainable AI Specialization on Coursera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNv9ZXSOY_hC"
   },
   "source": [
    "# Saliency Maps üñºÔ∏è\n",
    "\n",
    "If you experience high latency while running this notebook, you can open it in Google Colab:\n",
    "\n",
    "[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/explainable-machine-learning/explainable-ml/blob/main/saliency_maps.ipynb)\n",
    "\n",
    "Pixel attribution highlights the pixels relevant to an image classification by a neural network. Visualizations via the vanilla gradient are also known as saliency maps.\n",
    "\n",
    "### How does it work?\n",
    "Calculate the gradient of the loss function for the class of interest with respect to the input pixels\n",
    "\n",
    "Process:\n",
    "1. Perform a forward pass of image of interest\n",
    "2. Compute the gradient of the class score of interest with respect to the input pixels (set all other classes to zero)\n",
    "3. Visualize the gradients (show absolute values or highlight negative and positive contributions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K5w5_y0KQmmM",
    "outputId": "7fd18a60-7852-42b4-e3b8-a74cab813846"
   },
   "outputs": [],
   "source": [
    "!pip install numpy==1.25.2 matplotlib==3.7.1 tensorflow==2.14.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: When you run the code block below, you may get a warning \"Cannot find TensorRT\". Don't worry about this, it is only required if you need a GPU, which this lab does not need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tNfM_DMTZve5"
   },
   "outputs": [],
   "source": [
    "# Basic\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Model Utils\n",
    "import tensorflow as tf\n",
    "\n",
    "# Data Utils\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from keras.utils import get_file\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Fyh0EwiaXCL"
   },
   "source": [
    "#### Tensorflow Terminology: gradient tape\n",
    "\n",
    "A **gradient tape** is a TensorFlow mechanism for automatic differentiation. We use it to record operations for which we want to compute gradients, typically within the context of training a neural network. When we perform operations inside a tf.GradientTape() context, TensorFlow keeps track of all the computations that occur on tensors that are \"watched\" by the tape.\n",
    "\n",
    "Here gradient tape is used to compute the gradients of the model's predictions with respect to the input image tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hFAGkT8YaA2Z"
   },
   "outputs": [],
   "source": [
    "# Function to generate a saliency map for an input image based on a given model\n",
    "\n",
    "def generate_saliency_map(model, img):\n",
    "    # Convert the input image to a TensorFlow variable\n",
    "    x = tf.Variable(img)\n",
    "\n",
    "    # Add an extra dimension to the image tensor to match the model's input shape\n",
    "    x = tf.expand_dims(x, axis=0)\n",
    "\n",
    "    # Preprocess the image according to ResNet50 requirements\n",
    "    x = tf.keras.applications.resnet50.preprocess_input(x)\n",
    "\n",
    "    # Create a gradient tape context to record operations for automatic differentiation\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Watch the input tensor to calculate gradients\n",
    "        tape.watch(x)\n",
    "\n",
    "        # Forward pass: get model predictions for the input image\n",
    "        preds = model(x)\n",
    "\n",
    "        # Find the index of the highest predicted class probability\n",
    "        top_pred_index = tf.argmax(preds[0])\n",
    "\n",
    "    # Calculate the gradients of the top prediction with respect to the input image\n",
    "    grads = tape.gradient(preds, x)\n",
    "\n",
    "    # Compute the saliency map by taking the maximum absolute gradient across color channels\n",
    "    saliency = tf.reduce_max(tf.abs(grads), axis=-1)[0]\n",
    "\n",
    "    # Return the saliency map and the index of the top predicted class as a numpy array\n",
    "    return saliency, top_pred_index.numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZADOLtw8b0dw"
   },
   "source": [
    "We will load a pre-trained model, [ResNet50](https://www.tensorflow.org/api_docs/python/tf/keras/applications/ResNet50)\n",
    "\n",
    "and a test image from the [ImageNetV2](https://www.tensorflow.org/datasets/catalog/imagenet_v2) dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet50 pre-trained model\n",
    "model = tf.keras.applications.ResNet50(weights='imagenet', include_top=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following codeblock can be used outside of the Coursera lab environment to load the ImageNetV2 dataset. We have pre-saved an image and label for you to use for the remainder of the code. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "AiyORY7Aa9dZ"
   },
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "index = 1 #Change the index to get a different image\n",
    "\n",
    "# Load dataset from ImageNetV2\n",
    "dataset, info = tfds.load('imagenet_v2', with_info=True, split=\"test[:5%]\", as_supervised=True)\n",
    "for img, label in dataset.take(index):\n",
    "    img = tf.image.resize(img, (224, 224))\n",
    "    img = img.numpy().astype(np.float32)\n",
    "\n",
    "# Download the ImageNet class index file\n",
    "class_index_path = get_file('imagenet_class_index.json', 'https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json')\n",
    "\n",
    "# Load ImageNet class labels\n",
    "with open(class_index_path) as f:\n",
    "    class_idx = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pre-saved image, label, and class labels for ImageNet. If this notebook is run outside of the Coursera Labs environment, this code can be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 15 #available indices: 1, 4, 5, 10, 15\n",
    "\n",
    "# Load the image and label\n",
    "img = np.load(f'image_{index}.npy')\n",
    "label = np.load(f'label_{index}.npy')\n",
    "\n",
    "# Load the ImageNet class labels\n",
    "with open('imagenet_class_index.json') as f:\n",
    "    class_idx = json.load(f)\n",
    "\n",
    "print(\"Image shape:\", img.shape)\n",
    "print(\"Label:\", label)\n",
    "print(\"Class index:\", class_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4wxUuaDOW_XY"
   },
   "outputs": [],
   "source": [
    "# Generate saliency map\n",
    "saliency_map, top_pred_index = generate_saliency_map(model, img)\n",
    "\n",
    "# Map the index to class label\n",
    "predicted_class = class_idx[str(top_pred_index)][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626
    },
    "id": "eHr2fgksbPKw",
    "outputId": "dfd1a970-82e6-4c82-dd13-3f37ece7bb04"
   },
   "outputs": [],
   "source": [
    "# Display the original image\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Original Image')\n",
    "plt.imshow(img.astype(np.uint8))\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the saliency map\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(saliency_map, cmap='viridis')\n",
    "plt.title(\"Saliency Map\")\n",
    "plt.suptitle(f\"Predicted object class: {predicted_class}\")\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
